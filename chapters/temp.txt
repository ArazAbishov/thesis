Split and concat operations are fundamental for the design of parallel collections frameworks, such as Scala's parallel collections, (TODO: more examples), \todo{ref}. Hence, \rrbtree{} based vector with O(log(n)) split and concat operations, is a promising candidate for parallel computation. 

In this section, we will compare performance of naive and efficient concatenation algorithms in parallel tests. Optimisations such as inline standard vector and transience will be studied as well. Beyond that, the overall performance of \rrbtree{} based solutions will be compared to \stdvec{}. 

Tests will be executed over \rrbvec{}, \pvec{}, and \stdvec{} implementations. Unfortunately, \imrsvec{} does not support IntoParallelIterator trait implementation as a feature. Hence, it has been excluded from evaluation. 

Benchmarks are parameterized over size of vector, as well as count of threads, and the split factor \todo{ref}. 

% Evaluation chapter; Parallel vector

%   - Transience:
%    - Intro: Describes what is the librrb, and what can be configured in it (branching factor, transience). Described how the library could be configured. 
%    - Threading: transients in the context of threads. Which library is used for threading? 
%    - Garbage collection: some sort of garbage collection must be performed to avoid memory leakage because of structural sharing. Which garbage collection algorithm are you going to use. 
%    - Atomicity of referenced counted pointers (ARC): Jean claims that it is not enough to rely on atomicity of Arc, as it only ensures atomic access to reference count, but not underlying object itself. You need to verify this on your side. See the blog posts and docs of the Rust's std lib.

Results:
%  - As different optimisations may yield different performance, five different optimisation permutations were measured. Denotes a shorthands for them for simplicity, i.e. direct append (D) , direct append with tail (DT), etc. 
%  - MOTE: the presented results are MEDIAN values, not MEAN. Uses mean only for concat, as INTERQUARITLE range was very large. 
%  - NOTE: developed own solution for measuring memory usage. 
%  - NOTE: uses percentage for performance comparison
%  - Impact of garbage collection on performance: vec does not use GC, while pvec does (in a form of arc)
%  - NOTE: branching factor effect on performance
%  - TODO: take into account that you have not implemented display optimization
%  - TODO: check if you can reason about performance in relative terms, such as 2.3x, etc (does it make sense to take averages of runtimes and divide them by count)
%  - NOTE: However, the plotted lines have the same trend, so future work could attempt to properly benchmark concatenation with different inputs and different branching factors.
%  - The overhead of having a type attached to each node, as well as precense or abcense of the size table make a difference. Jean has calculated exactly by how much. 


- Hopefully, further optimizations will mean that sequential fallback is less necessary – but it’s worth pointing out that higher-level APIs like the parallel iterator I alluded to earlier can also handle the sequential fallback for you, so that you don’t have to actively think about it.
- Combinators (not operators). That's what iter and par_iter exposes afaik.
- non-associativity of parallel collection frameworks
- parallel collections of prokopec (presentation)