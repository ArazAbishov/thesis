\chapter{Performance evaluation}

In this chapter, I will introduce a methodology for performance evaluation of \rrbvec{}, \pvec{} and their variants, in comparison to implementations from \imrsvec{} and the Rust's standard library. We will look at the details of these three stages:

\begin{itemize}
    \item First, a methodology for collecting reliable measurements. 
    \item Then identifying directions for performance comparisons. 
    \item Finally, defining benchmarks. 
\end{itemize}

To begin with, I will present a notion of benchmarking framework, before diving into details of specific profiling tests. 

\section{Methodology}
Even though \bigo{} \todo{Use a word representation of Big-O} is a useful tool for reasoning about performance in theory, it often is not accurate enough for evaluating real-world performance. First, it disregards constant factors as they are not significant for the growth rate of functions. Second, it does not consider the architecture of CPU and memory \todo{ref}, which indeed influences performance. Furthermore, it also applies to software, such as operating systems, schedulers, virtual machines, et cetera. Hence, often algorithms which are expected to be equally fast based on \bigo{}, may differ substantially in real-world performance. 

This leads us to a need for an experimental performance analysis approach, which would involve executing tests on the actual hardware and software. This, however, introduces another set of unique challenges. For instance, depending on the workload, operating systems may allocate more resources for high demanding tasks, by reducing runtime for others \todo{ref}. Such non-deterministic behavior may lead to profiling results which vary from run to run significantly, which defeats the purpose of having them. 

Benchmarking frameworks were introduced to solve those problems. They are designed to get stable measurements by executing the same test thousands of times. Some of them, such as criterion \todo{ref} for Haskell and Rust, JMH \todo{ref} for Java, and ScalaMeter for Scala, introduce statistical methods for the detection and elimination of exceptionally different runs, known as outliers. 

\subsection{Benchmarking frameworks for Rust}

There are several benchmarking frameworks available for Rust, and unfortunately, none of them have reached a stable release yet. However, some of them are being actively used in the Rust community and proven to produce reliable results.  

In our case, there are several criteria which a good framework has to meet:

\begin{itemize}
    \item Collects multiple samples where each sample consists of multiple runs to ensure consistent results. 
    \item Detection and elimination of outliers.     
    \item A way for setting up a benchmark before each run. 
    \item A way for preventing compiler optimizing benchmark code away.     
\end{itemize}

\subsubsection*{Rust's benchmark tests}
The Rust's testing framework provides an experimental feature which enables developers to write test benchmarks. Those benchmarks are executed thousands of times until results are stabilized. Also, it provides a black-box function \footnote{Black box function contains inline assembly instructions, which compiler cannot make any assumptions about. Hence, it prevents the compiler from optimizing the code which otherwise would be considered "dead" or unused.} which is opaque for the compiler. 

However, it does not detect and eliminate anomalies. It also does not provide APIs for setup routines, which makes it impossible to create benchmarks which rely on certain preconditions.

% ToDo: consider talking about measurement of time for dropping items
\subsubsection*{Criterion for Rust}
Criterion for Rust \todo{ref}, not to be confused with Criterion for Haskell \todo{ref}, is a powerful and statistically rigorous tool for profiling code. It features outlier elimination, setup routines, and is capable to generate graphs provided that gnuplot is installed \todo{ref}. it is available for the stable Rust compiler. Thus, Criterion was chosen as a benchmarking framework for this project. 

\subsection{Execution environment}
All benchmarks were executed on a computer \todo{table with hardware, software} with a quad-core Intel Core i5-6600 processor with hyperthreading, 16GB of DDR4 RAM and 250GB solid-state drive. The operating system of the choice is Ubuntu 18.04 with nightly Rust compiler version \todo{Rust version}.

\subsection{Configuration and input size}
\todo{section}

\section{Benchmarking directions}
% ToDo: you have completely forgotten about branching factor, and it being a standalone feature
% ToDo: you haven't talked about input size and configuration of benchmarks (what will be the input size). You can steal input numbers from scala paper, and then tweak them to run for reasonable amount of time. 

To understand how effective certain optimizations are, we need to evaluate various configurations of the persistent vector. Additionally, implementations from \imrsvec{} and the standard library will be tested too. All vector variants are specified in table \todo{ref}. 

% ToDo: try to name types after the name of types in actual code, otherwise thins will get very confusing very fast. Also, I don't think it is important to show distinction between Rc / Arc flavors of implementations, because it just introduces more confusion. 
\begin{center}
\begin{tabular} { |l| p{10cm} | }
    \hline
    STD Vec & Vec from the Rust's standard library. \\ \hline
    \rbvec{} & \rbtree{} based vector. \\ \hline
    \rrbvec{} & \rrbtree{} based vector. \\ \hline
    \pvec{} & \rrbtree{} based vector with dynamic internal representation. \\ \hline
    \imrsvec{} & \rrbtree{} based vector from third party library \imrsvec{}. \\
    \hline        
\end{tabular}
\end{center}

% \begin{wip}
    % For the purpose of comparison, the measurements are taken against the standard vector, as well as the \rrbtree based persistent vector implementation from the third party library named \emph{im-rs}, which has been introduced at the time of writing this paper. The persistent vector presented in this work, has been evaluated using both non-atomic and atomic reference counted pointers, as well as with and without small sized vector based optimization. 
% \end{wip}

In general, benchmarks described below could be categorized into two groups:

\begin{itemize}
    \item First, serial benchmarks for profiling core operations in a sequential environment. They will be executed both against threadsafe and non-threadsafe variants of the vector. 
    \item Second, concurrent benchmarks which will be executed against only thread-safe variants of the vector. The goal is to check whether there are benefits of using fast split and combine operations of \rrbvec{}.
\end{itemize}


\subsection{RB and RRB Vectors}
As relaxed balanced tree is not perfectly balanced and involves the use of size tables for the radix search, it is expected to be somewhat slower in all core operations. This, however, is not true from the perspective of asymptotic analysis, where constant factors are neglected. The goal of benchmarks, in this case, is to reveal the overhead induced by relaxed nodes. 

Before each benchmark run, an instance of \rrbvec{} will be prepared by concatenating pseudo-random small vectors together. The amount of relaxed nodes is in part affected by the size of the vector. Both threadsafe and non-threadsafe variants will be compared. 

% ToDo: how to consistenly generate RRB Vectors using pseudo randomly sized small vectors? Can you get access to benchmarks from paper anywhere? 
% ToDo: add list of benchmarks which will be evaluating different core operations. 

\subsection{Unique access or transience}
While \rrbvec{} performs very well as a persistent data structure, it is not very optimal when properties of persistence are not required. An example is a function which creates and returns an instance of \rrbvec{}, where all versions except the returned one are disregarded.

Luckily, the persistent vector presented in this project takes advantage of Rust's compiler capabilities of tracking object aliasing. Thus, it avoids redundant copying on mutation if the given object is uniquely accessed. This behavior is somewhat similar to transience in the Clojure's persistent vector, but not entirely identical \todo{see reference}. 

In Rust, non-transient, persistent behavior can be enforced by cloning the object before performing a mutation. The goal is to measure the overhead of using clone operation in the persistent vector. 

\subsection{Dynamic internal representation}
As one of the suggested optimizations in \todo{ref to scala paper}, a standard vector can be used to improve the performance of small-sized \rrbvec{}. The size recommended for using the standard vector representation is 4096. However, dynamically switching representation during runtime comes at a cost, which potentially may offset the benefits. 

The purpose of profiling this optimization is to understand whether it improves performance in practice, and in which use cases. The range of problem sizes will include small values. 

\todo{describe an experiment; i.e. how many threads, split factor, problem sizes, etc.}
\todo{how number of threads is configured in rayon: 1, 2, 4, 8, 16, 32 and 64}
\todo{which experiments will you run?}

\subsection{Memory overhead}
\todo{tbd}

\subsection{Rc vs Arc}
Since atomic reference-counted pointers are claimed to introduce additional overhead in comparison to their non-threadsafe counterpart, the goal is to check how significant is the difference. 

As a part of all sequential benchmarks, both threadsafe and non-threadsafe variants will be evaluated. Rc based flavor will not be present in parallel benchmarks, as the Rust's compiler prevents non-threadsafe types being used across threads. 

% Benchmarks which make use of .clone() operation somehow? 

\section{Parallel vector}
One of the claims is that \rrbvec{} is very efficient when it comes to split and concatenate operations. The data parallelism frameworks, such as Rayon \todo{ref}, Cilk \todo{ref}, and Scala's parallel collections \todo{ref}, split the work into smaller chunks to ensure good parallelism. Thus, fast split and concat operations are critical for optimal performance. 

In this section, we will first take a look at how Rayon splits and distributes the work across threads, as well as available configuration parameters. Then, section \todo{} introduces tests for benchmarking the overall performance of persistent and standard vectors:

\begin{itemize}    
    \item Check if a word is a palindrome. 
    \item Scalar product of two vectors.
    \item Iterating over and incrementing a vector of integers.
\end{itemize}

All the tests will be executed on 1, 2, 4, 8, and 16 threads. 

Unlike the measurements presented from the sequential benchmarks, the parallel ones inlude the run time of both vector operations and Rayon. As the objective is the overall performance comparison, this is considered to be an acceptable tradeoff. 

The results will be used to evaluate the effectivness of following optimizations:
\begin{itemize}
    \item The effect of relaxed concat and split operations of \rrbvec{} on the overall performance. 
    \item Dynamic internal representation of \pvec{}.     
\end{itemize}

\subsection{Rayon}

% * what do iterators and parallel iterators expose as API
%  * what is a combinator?
%    * assosiativity of combinators in iter and par_iter 

The idea of Rayon, a data parallelism library for Rust, is to turn sequential code into parallel with as little work as possible. Loops and iterators are often used to process collections sequentially. Rayon on the other hand, offers a potentially more efficient alternative to them in the form of parallel iterators. It takes advantage of modern processors, by dividing the work between available cores when it is considered to be beneficial. 

The power of iterators in Rust is in the operations which it provides over its elements. Structures which implement those operations are called combinators. They can be chained and the result of execution is passed from one combinator to another. 

% * difference between behavior of iterators and par iterators
%  * non deterministic order of execution
%  * the types passed between threads have to be send + sync (? optional)

Parallel iterators expose similar set of operators, even though not entirely. As iterators process values sequentially, there is a set of combinators which expect values to be emitted in particular order. As the parallel iterators are designed to process data in any order, inherentely sequential combinators are simply not applicable. 

Another limitation which parallel iterators impose, is that type of values which it works with have to implement the \emph{Send} trait. It means using non-threadsafe types such as \emph{Rc} in combination with Rayon is prohibited. 

% * Example of iter and par_iter

One of the Rayon's components, fork/join framework, is responsible for dividing and distributing the work between threads. When parallel iterator receives values from a collection like vector, Rayon attempts to repeatedely divide the work into chunks among threads until the chunk is small enough for a single thread. 

% Example of calls to the join

% * collection is converted to a parallel iterator
% * how the work is split between threads
%   * fundamental split / combine operations
%   * connection between ParallelIterator and RrbVec

It is important to note that the \emph{rayon::join} function \emph{may} execute clojures in parallel. It decides whether it will be beneficial to parallelize the work, depending on the count of available threads and the work load. 

% * what controls the count of threads
%   * Configuring thread count in the underlying threadpool

The default count of threads used by Rayon is equal to the count of worker threads available in the system. Usually this is the number of cores available in CPU. Rayon provides mechanism for configuring the size of the underlying threadpool, which will be used in benchmarks to check how the threadcount affects results. 

\begin{figure}
    \caption{Visualization of work splitting in Rayon.}
    \label{fig:rayon-work-splitting}

    \center
    \begin{tikzpicture}[
        font=\ttfamily,
        array/.style={
            matrix of nodes,
            nodes={draw, minimum size=7mm, fill=green!30},
            column sep=-\pgflinewidth, 
            row sep=0.5mm, 
            nodes in empty cells,        
            row 1 column 1/.style={nodes={draw}}
        }]
                
        \matrix[array] (array) { 
            1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 \\
        };            
        
        \draw[|-|]([yshift=-4mm,xshift=1mm]array-1-1.south west) -- node[above,font=\tiny,outer sep=0mm] {12} ([yshift=-4mm,xshift=-1mm]array-1-12.south east);

        \draw[|-|]([yshift=-8mm,xshift=1mm]array-1-1.south west) -- node[above,font=\tiny,outer sep=0mm] {6} ([yshift=-8mm,xshift=-1mm]array-1-6.south east);
        \draw[|-|]([yshift=-8mm,xshift=1mm]array-1-7.south west) -- node[above,font=\tiny,outer sep=0mm] {6} ([yshift=-8mm,xshift=-1mm]array-1-12.south east);

        \draw[|-|]([yshift=-12mm,xshift=1mm]array-1-1.south west) -- node[above,font=\tiny,outer sep=0mm] {3} ([yshift=-12mm,xshift=-1mm]array-1-3.south east);
        \draw[|-|]([yshift=-12mm,xshift=1mm]array-1-4.south west) -- node[above,font=\tiny,outer sep=0mm] {3} ([yshift=-12mm,xshift=-1mm]array-1-6.south east);
        \draw[loosely dotted]([yshift=-12mm,xshift=1mm]array-1-7.south west) -- ([yshift=-12mm,xshift=-1mm]array-1-12.south east);

        \draw[|-|]([yshift=-16mm,xshift=1mm]array-1-1.south west) -- node[above,font=\tiny,outer sep=0mm] {2} ([yshift=-16mm,xshift=-1mm]array-1-2.south east);
        \draw[|-|]([yshift=-16mm,xshift=1mm]array-1-3.south west) -- node[above,font=\tiny,outer sep=0mm] {1} ([yshift=-16mm,xshift=-1mm]array-1-3.south east);
        \draw[loosely dotted]([yshift=-16mm,xshift=1mm]array-1-4.south west) -- ([yshift=-16mm,xshift=-1mm]array-1-12.south east);

        \draw[|-|]([yshift=-20mm,xshift=1mm]array-1-1.south west) -- node[above,font=\tiny,outer sep=0mm] {1} ([yshift=-20mm,xshift=-1mm]array-1-1.south east);
        \draw[|-|]([yshift=-20mm,xshift=1mm]array-1-2.south west) -- node[above,font=\tiny,outer sep=0mm] {1} ([yshift=-20mm,xshift=-1mm]array-1-2.south east);
        \draw[loosely dotted]([yshift=-20mm,xshift=1mm]array-1-2.south west) -- ([yshift=-20mm,xshift=-1mm]array-1-12.south east);    
        
        \draw ([xshift=1mm]array-1-12.east)--++(0:3mm) node [right]{ Vector };
    \end{tikzpicture}

\end{figure}

% * the work distribution
%   * static chunking vs dynamic chunking:
%       Work distribution, known as static chunking (giving each processor N / P sized chunk), is optimal when the amount of work per element takes the same amount of time. NOTE: Rayon is using adaptive work stealing algorithm, which ensures better load balancing when it takes different amount of time to process each chunk. NOTE: provides a code snippet of how concatenation is implemented 
%     * fork join framework
%     * potential parallism
%     * work stealing

In perfect world the chunks of work split between threads take the same amount of time to process. In reality this is often not the case, resulting in some threads idling. In Rayon, each thread has a queue of work attached to it. It keeps processing the queue until it becomes empty. In order to avoid idling, the thread which has finished processing its queue can steal work from another thread. This technique is know as work stealing and is used as the main mechnasim for work distribution in Rayon. 

% * Example of a fork/join tree, which depicts work distribution. 

% * combining results
%   * combinators used to aggregate results: reduce
%   * process values individually, like for_each


% Rayon can be divided into three layers:
% \begin{itemize}
%     \item Parallel iterators.
%     \item The fork / join framework.
%     \item Threadpool.
% \end{itemize}

Data parallelism, however, is not applicable to algorithms which rely on the order of execution. The reason is that parallel iterators process values in non-deterministic order. 

To ensure optimal performance, Rayon keeps dividing the work between threads, until the resulting chunk of the work is sufficiently small to be executed on a single thread. 

Rayon's parallel iterators provide methods for hinting the scheduler how large the chunk of work should be: 
\begin{itemize}
    \item with\_min\_len: sets the minimum size of the chunk
    \item with\_max\_len: sets the maximum size of the chunk
\end{itemize}

\todo{Explain the effects of using those two methods}

The count of threads in the underlying threadpool is equal to the count of CPU cores. On the systems with hyperthreading enabled this equals the number of logical cores and not the physical ones. 

\paragraph*{Load balancing}

\subsection{Benchmarks}

\paragraph*{Check if a word is a palindrome}
\todo{content}

\paragraph*{Scalar product of two vectors}
\todo{content}

\paragraph*{Iterating over and incrementing a vector of integers}
\todo{content}

\section{Presentation of results}
\todo{section}

\section{Reproducing results}
\todo{tbd}
