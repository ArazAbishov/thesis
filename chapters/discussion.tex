\newcommand{\relaxed}{\emph{(r)}}

\chapter{Results and discussion}
In this chapter, we will take a look at the results of the sequential and parallel benchmarks, and discuss whether proposed\todo{ref} performance optimizations are effective. 

The sequential benchmark results are subdivided per the core operation and listed under the \ref{sec:perf-seq} section. Performance of the threadsafe implementation is evaluated separately.  

The parallel benchmark results in section \ref{sec:perf-par} are not discussed by operation, as they focus on the overall performance comparison of vectors rather than particular operation in isolation. 

The results are discussed to address the following points:
\begin{itemize}
    \item Effect of \rrbtree{} relaxation on concatenation, splitting, and other core operations of \rrbvec{} and \pvec{}. 
    \item The impact of the unique access optimization on the performance of all vector implementations.
    \item Effectiveness of the dynamic internal representation.
\end{itemize}

\paragraph{Reading notes} 
Implementations that are prefixed with \relaxed{} in the figure legend were configured to use the relaxed \emph{rb} tree in the benchmark. If not specified, the vector is either balanced or is not based on a tree, like \stdvec{}. 

\section{Performance of the core operations}
\label{sec:perf-seq}
This section contains performance numbers for the non-threadsafe implementations of \stdvec{}, \rbvec{}, \rrbvec{}, \pvec{}, and \imrsvec{}. Threadsafe variants are evaluated and discussed separately in section \ref{sec:perf-rc-vs-arc}. 

\subsection{Indexing}
Figures for the index operation are separated by sequential and random access, where the sequential benchmark results are subdivided into the index and iterator figures. 

\subsubsection*{Index sequentially}
\begin{figure}[!htbp]

    \center
    \begin{adjustbox}{width=\textwidth}
    \begin{tikzpicture}
        \tikzstyle{every node}=[
            font=\scriptsize, 
            inner sep=2pt,
            outer sep=0pt            
        ]        

        \pgfplotstableread[col sep=comma]{data/index_sequentially/imrs-vector-balanced.csv}\idxseqimrsvectorbalanced;
        \pgfplotstableread[col sep=comma]{data/index_sequentially/imrs-vector-relaxed.csv}\idxseqimrsvectorrelaxed;
        \pgfplotstableread[col sep=comma]{data/index_sequentially/pvec-balanced.csv}\idxseqpvecbalanced;
        \pgfplotstableread[col sep=comma]{data/index_sequentially/pvec-relaxed.csv}\idxseqpvecrelaxed;
        \pgfplotstableread[col sep=comma]{data/index_sequentially/rbvec-balanced.csv}\idxseqrbvecbalanced;
        \pgfplotstableread[col sep=comma]{data/index_sequentially/rrbvec-relaxed.csv}\idxseqrrbvecrelaxed;
        \pgfplotstableread[col sep=comma]{data/index_sequentially/std-vec.csv}\idxseqstdvector;

        \pgfplotstableread[col sep=comma]{data/iterator_next/imrs-vector-balanced.csv}\itrnextimrsvectorbalanced;
        \pgfplotstableread[col sep=comma]{data/iterator_next/imrs-vector-relaxed.csv}\itrnextimrsvectorrelaxed;
        \pgfplotstableread[col sep=comma]{data/iterator_next/pvec-balanced.csv}\itrnextpvecbalanced;
        \pgfplotstableread[col sep=comma]{data/iterator_next/pvec-relaxed.csv}\itrnextpvecrelaxed;
        \pgfplotstableread[col sep=comma]{data/iterator_next/rbvec-balanced.csv}\itrnextrbvecbalanced;
        \pgfplotstableread[col sep=comma]{data/iterator_next/rrbvec-relaxed.csv}\itrnextrrbvecrelaxed;
        \pgfplotstableread[col sep=comma]{data/iterator_next/std-vec.csv}\itrnextstdvector;
        
        \begin{groupplot}[
            group style={group size=2 by 1, horizontal sep=56pt,},                   
            xlabel={Vector size (log scale)},
            ylabel={Mean time (log scale) [\millis{}]},
            yticklabels={0, \micros{0.01}, \micros{0.1}, \micros{1}, 0.01, 0.1, 1, 10, 100},
            xticklabels={0, 10, 100, \kilo{1}, \kilo{10}, \kilo{100}, \mega{1}},
            ymajorgrids=true,
            xmajorgrids=true,
            grid style=dashed,
        ]
            \nextgroupplot[
                xmode=log,
                ymode=log,
                title={Index sequentially},
                legend columns=4,
                legend style={
                    at={(1.12,-0.2)},
                    anchor=north
                }
            ]
            \addplot[ultra thin, color=morange, mark=*, mark size=1.2pt,] table {\idxseqstdvector};            
            \addplot[ultra thin, color=mred, mark=*, mark size=1.2pt,] table {\idxseqrbvecbalanced};            
            \addplot[ultra thin, color=mred, mark=pentagon, mark size=1.6pt,] table {\idxseqrrbvecrelaxed};             
            \addplot[ultra thin, color=mgreen, mark=square, mark size=1.6pt,] table {\idxseqpvecbalanced};            
            \addplot[ultra thin, color=mgreen, mark=diamond*, mark size=1.2pt,] table {\idxseqpvecrelaxed};            
            \addplot[ultra thin, color=mpurple, mark=pentagon*, mark size=1.2pt,] table {\idxseqimrsvectorbalanced};
            \addplot[ultra thin, color=mpurple, mark=square, mark size=1.6pt,] table {\idxseqimrsvectorrelaxed};
            \legend{\stdvec{}, \rbvec{}, \rrbvec{} \relaxed{}, \pvec{}, \pvec{} \relaxed{}, \imrsvec{}, \imrsvec{} \relaxed{}}
    
            \nextgroupplot[xmode=log,ymode=log,title={Iterator}]
            \addplot[ultra thin, color=morange, mark=*, mark size=1.2pt,] table {\itrnextstdvector};                     
            \addplot[ultra thin, color=mred, mark=*, mark size=1.2pt,] table {\itrnextrbvecbalanced};            
            \addplot[ultra thin, color=mred, mark=pentagon, mark size=1.6pt,] table {\itrnextrrbvecrelaxed}; 
            \addplot[ultra thin, color=mgreen, mark=square, mark size=1.6pt,] table {\itrnextpvecbalanced};
            \addplot[ultra thin, color=mgreen, mark=diamond*, mark size=1.2pt,] table {\itrnextpvecrelaxed};
            \addplot[ultra thin, color=mpurple, mark=pentagon*, mark size=1.2pt,] table {\itrnextimrsvectorbalanced};
            \addplot[ultra thin, color=mpurple, mark=square, mark size=1.6pt,] table {\itrnextimrsvectorrelaxed};      
        \end{groupplot}
    
    \end{tikzpicture} 
    \end{adjustbox}

    \caption{Benchmark results of index sequentially and iterator.}
    \label{fig:index-sequentially}
\end{figure}

Unsurprisingly, the \stdvec{} shows the best results in this test. As it is backed by a contiguous chunk of memory, it takes full advantage of CPU cache locality. Besides, its structure is not affected by the method used to build it, when \rbtree{} and \rrbtree{} based vectors are.

Both balanced and unbalanced \imrsvec{} variants tend to be slower in comparison to \rrbvec{} in the \range{[100, \mega{1}]} input range by a factor of 2.06. For smaller inputs, \rrbvec{} it is slightly faster with a difference of 1.18. 

\paragraph{Balanced vs relaxed variants}
The difference between the balanced \rbvec{} and relaxed \rrbvec{} becomes noticeable as the problem size grows. The balanced variant is faster than the relaxed one by a factor of 2.68 in the \range{[100, \mega{1}]} input range. This is expected because \rrbvec{} introduces relaxed nodes, which rely on the size tables to compute the path to the value. 

This, however, is not the case for small problem sizes in the \range{[0, 100]} range, for which the concatenating algorithm produces a balanced tree. Hence, both balanced and relaxed vectors demonstrate similar performance in that range. 

\paragraph{Dynamic internal representation}
\pvec{} switches its internal representation from the standard vector to \rrbvec{} as the size gets over 1024 elements. This is evident from the plot \ref{fig:index-sequentially}, where \pvec{} is 2.31 faster than \rbvec{}, but slower than \stdvec{} by a factor of 2.61. It is slower because of the overhead induced by acquiring a mutable reference to \rc{} pointer. As soon as the threshold is passed, the difference in performance between \pvec{} and \rrbvec{} becomes negligible. 

\subsubsection*{Iterator}
Results of the iterator benchmarks show approximately 10 fold improvement in performance over sequential indexing. This is expected, as iterators read the contents of the tree by chunks rather than by index. 

\stdvec{} shows the best results, with a difference of 1.98 on average compared to \pvec{}, and 9.12 in relation to \rrbvec{}. \imrsvec{} is 1.47 ahead of \rrbvec{} in the [10, 100] range. 

\paragraph{Balanced vs relaxed variants}
As iterator does not use size tables for index calculation for \rrbvec{}, it performs identically well compared to \rbvec{}. The same applies to \imrsvec{}. 

\subsubsection*{Index randomly}
\begin{figure}[t]
    
    \center    
    \begin{tikzpicture} 
        \pgfplotstableread[col sep=comma]{data/index_randomly/imrs-vector-balanced.csv}\imrsvectorbalanced;
        \pgfplotstableread[col sep=comma]{data/index_randomly/imrs-vector-relaxed.csv}\imrsvectorrelaxed;
        \pgfplotstableread[col sep=comma]{data/index_randomly/pvec-balanced.csv}\pvecbalanced;
        \pgfplotstableread[col sep=comma]{data/index_randomly/pvec-relaxed.csv}\pvecrelaxed;
        \pgfplotstableread[col sep=comma]{data/index_randomly/rbvec-balanced.csv}\rbvecbalanced;
        \pgfplotstableread[col sep=comma]{data/index_randomly/rrbvec-relaxed.csv}\rrbvecrelaxed;        
        \pgfplotstableread[col sep=comma]{data/index_randomly/std-vec.csv}\stdvector;
    
        \begin{loglogaxis}[         
            use units,                     
            smooth,        
            width=300pt,
            title={Index randomly},
            xlabel={Vector size (log scale)},
            ylabel={Mean time (log scale) [\millis{}]},                
            ymajorgrids=true, 
            xmajorgrids=true,
            grid style=dashed,            
            legend pos=north west,        
            legend style={draw=none,fill=none,font=\footnotesize},
            legend cell align=left,             
            yticklabels={0, \micros{0.1}, \micros{1}, 0.01, 0.1, 1, 10, 100},
            xticklabels={0, 10, 100, \kilo{1}, \kilo{10}, \kilo{100}, \mega{1}},
        ]
            \addplot[thin, color=morange, mark=*,] table {\stdvector};             
            \addlegendentry{\stdvec{}}
    
            \addplot[thin, color=mred, mark=*,] table {\rbvecbalanced};
            \addlegendentry{\rbvec{}}
    
            \addplot[thin, color=mred, mark=pentagon,] table {\rrbvecrelaxed}; 
            \addlegendentry{\rrbvec{} \relaxed{}}
    
            \addplot[thin, color=mgreen, mark=square,] table {\pvecbalanced};
            \addlegendentry{\pvec{}}

            \addplot[thin, color=mgreen, mark=diamond*,] table {\pvecrelaxed};
            \addlegendentry{\pvec{} \relaxed{}}
    
            \addplot[thin, color=mpurple, mark=pentagon*,] table {\imrsvectorbalanced};
            \addlegendentry{\imrsvec{}}
    
            \addplot[thin, color=mpurple, mark=square,] table {\imrsvectorrelaxed};
            \addlegendentry{\imrsvec{} \relaxed{}} 
        \end{loglogaxis}     
    \end{tikzpicture}     

    \caption{Benchmarking results of indexing randomly.}
    \label{fig:index-randomly}
\end{figure}

\paragraph{Balanced vs relaxed variants}
\rbvec{} outperforms \rrbvec{} by 1.90 in the \range{[100, \mega{1}]} range. Both relaxed \rrbvec{} and \imrsvec{} are equally fast with insignificant marginal differences.

\paragraph{Dynamic internal representation}
It is clear that \pvec{} is as fast as \stdvec{} up to the size of 1024, right after which it becomes slower and aligns with the \rrbvec{}. Even then, however, performance difference between \stdvec{} and \pvec{} is not significant, remaining quite consistent over the rest of the input range at 1.99. 

\subsection{Updating}
Results of the update operation benchmarks are divided by sequential and random access, and complemented with evaluation with the use of clone operation. 

\subsubsection*{Update sequentially}
\begin{figure}[!htbp]
    
    \center
    \begin{adjustbox}{width=\textwidth}
    \begin{tikzpicture}
        \tikzstyle{every node}=[
            font=\scriptsize, 
            inner sep=2pt,
            outer sep=0pt            
        ]

        \pgfplotstableread[col sep=comma]{data/update/imrs-vector-balanced.csv}\upimrsvectorbalanced;
        \pgfplotstableread[col sep=comma]{data/update/imrs-vector-relaxed.csv}\upimrsvectorrelaxed;
        \pgfplotstableread[col sep=comma]{data/update/pvec-balanced.csv}\uppvecbalanced;
        \pgfplotstableread[col sep=comma]{data/update/pvec-relaxed.csv}\uppvecrelaxed;
        \pgfplotstableread[col sep=comma]{data/update/rbvec-balanced.csv}\uprbvecbalanced;
        \pgfplotstableread[col sep=comma]{data/update/rrbvec-relaxed.csv}\uprrbvecrelaxed;
        \pgfplotstableread[col sep=comma]{data/update/std-vec.csv}\upstdvector;

        \pgfplotstableread[col sep=comma]{data/update_clone/imrs-vector-balanced.csv}\upclimrsvectorbalanced;
        \pgfplotstableread[col sep=comma]{data/update_clone/imrs-vector-relaxed.csv}\upclimrsvectorrelaxed;
        \pgfplotstableread[col sep=comma]{data/update_clone/pvec-balanced.csv}\upclpvecbalanced;
        \pgfplotstableread[col sep=comma]{data/update_clone/pvec-relaxed.csv}\upclpvecrelaxed;
        \pgfplotstableread[col sep=comma]{data/update_clone/rbvec-balanced.csv}\upclrbvecbalanced;
        \pgfplotstableread[col sep=comma]{data/update_clone/rrbvec-relaxed.csv}\upclrrbvecrelaxed;
        \pgfplotstableread[col sep=comma]{data/update_clone/std-vec.csv}\upclstdvector;        
        
        \begin{groupplot}[
            group style={group size=2 by 1, horizontal sep=56pt,},                   
            xlabel={Vector size (log scale)},
            ylabel={Mean time (log scale) [\millis{}]},            
            yticklabels={0, \micros{0.01}, \micros{0.1}, \micros{1}, 0.01, 0.1, 1, 10},
            xticklabels={0, 10, 100, \kilo{1}, \kilo{10}, \kilo{100}},            
            ymajorgrids=true, 
            xmajorgrids=true,         
            grid style=dashed,  
        ]
            \nextgroupplot[
                xmode=log,
                ymode=log,
                title={Update sequentially},
                legend columns=4,
                legend style={
                    at={(1.06,-0.2)},
                    anchor=north
                }
            ]
            \addplot[ultra thin, color=morange, mark=*, mark size=1.2pt,] table {\upstdvector};            
            \addplot[ultra thin, color=mred, mark=*, mark size=1.2pt,] table {\uprbvecbalanced};            
            \addplot[ultra thin, color=mred, mark=pentagon, mark size=1.6pt,] table {\uprrbvecrelaxed};                     
            \addplot[ultra thin, color=mgreen, mark=square, mark size=1.6pt,] table {\uppvecbalanced};  
            \addplot[ultra thin, color=mgreen, mark=diamond*, mark size=1.2pt,] table {\uppvecrelaxed}; 
            \addplot[ultra thin, color=mpurple, mark=pentagon*, mark size=1.2pt,] table {\upimrsvectorbalanced};            
            \addplot[ultra thin, color=mpurple, mark=square, mark size=1.6pt,] table {\upimrsvectorrelaxed};            
            \legend{\stdvec{}, \rbvec{}, \rrbvec{} \relaxed{}, \pvec{}, \pvec{} \relaxed{}, \imrsvec{}, \imrsvec{} \relaxed{}}
    
            \nextgroupplot[xmode=log,ymode=log,title={Update sequentially and cloning}]
            \addplot[ultra thin, color=morange, mark=*, mark size=1.2pt,] table {\upclstdvector};                     
            \addplot[ultra thin, color=mred, mark=*, mark size=1.2pt,] table {\upclrbvecbalanced};            
            \addplot[ultra thin, color=mred, mark=pentagon, mark size=1.6pt,] table {\upclrrbvecrelaxed}; 
            \addplot[ultra thin, color=mgreen, mark=square, mark size=1.6pt,] table {\upclpvecbalanced};
            \addplot[ultra thin, color=mgreen, mark=diamond*, mark size=1.2pt,] table {\upclpvecrelaxed};
            \addplot[ultra thin, color=mpurple, mark=pentagon*, mark size=1.2pt,] table {\upclimrsvectorbalanced};
            \addplot[ultra thin, color=mpurple, mark=square, mark size=1.6pt,] table {\upclimrsvectorrelaxed};                       
        \end{groupplot}
    \end{tikzpicture} 
    \end{adjustbox}

    \caption{Benchmarking results of updating values sequentially.}
    \label{fig:update-sequentially}
\end{figure}

% TODO: \paragraph{Balanced vs relaxed variants}

\paragraph{Dynamic internal representation}
In the benchmark of updating a vector without cloning, \pvec{} is faster than both variants of \rrbvec{} by a factor of 2.22 in the \range{[10, 1024]} size range. After switching the internal representation, it aligns with \rrbvec{}. 

When the clone operation is involved, \pvec{} outperforms \rrbvec{} in the \range{[80, 1024]} range by a factor of 1.6. 

\paragraph{Unique access or transience}
All vector implementations are faster when the clone operation is not used. The \stdvec{} shows the best results in all sizes, with the runner up \pvec{} being slower on average of 6.47. However, with the clone operation, the \stdvec{} is slightly faster only up to the size of 1024, after which it quickly degenerates due to a very inefficient clone. 

% TODO: mention the difference in perf of clone between rbvec, rrbvec, pvec and stdvec. Mention the role of path copying algorithms. 
\imrsvec{} was slower than \rrbvec{} in both tests, with and without clone operation used, by a factor of 1.73 and 1.5 correspondingly. 

\subsubsection*{Update randomly}
\begin{figure}[!htbp]
    
    \center
    \begin{adjustbox}{width=\textwidth}
    \begin{tikzpicture}
        \tikzstyle{every node}=[
            font=\scriptsize, 
            inner sep=2pt,
            outer sep=0pt            
        ]

        \pgfplotstableread[col sep=comma]{data/update_randomly/imrs-vector-balanced.csv}\upimrsvectorbalanced;
        \pgfplotstableread[col sep=comma]{data/update_randomly/imrs-vector-relaxed.csv}\upimrsvectorrelaxed;
        \pgfplotstableread[col sep=comma]{data/update_randomly/pvec-balanced.csv}\uppvecbalanced;
        \pgfplotstableread[col sep=comma]{data/update_randomly/pvec-relaxed.csv}\uppvecrelaxed;
        \pgfplotstableread[col sep=comma]{data/update_randomly/rbvec-balanced.csv}\uprbvecbalanced;
        \pgfplotstableread[col sep=comma]{data/update_randomly/rrbvec-relaxed.csv}\uprrbvecrelaxed;
        \pgfplotstableread[col sep=comma]{data/update_randomly/std-vec.csv}\upstdvector;

        \pgfplotstableread[col sep=comma]{data/update_clone_randomly/imrs-vector-balanced.csv}\upclimrsvectorbalanced;
        \pgfplotstableread[col sep=comma]{data/update_clone_randomly/imrs-vector-relaxed.csv}\upclimrsvectorrelaxed;
        \pgfplotstableread[col sep=comma]{data/update_clone_randomly/pvec-balanced.csv}\upclpvecbalanced;
        \pgfplotstableread[col sep=comma]{data/update_clone_randomly/pvec-relaxed.csv}\upclpvecrelaxed;
        \pgfplotstableread[col sep=comma]{data/update_clone_randomly/rbvec-balanced.csv}\upclrbvecbalanced;
        \pgfplotstableread[col sep=comma]{data/update_clone_randomly/rrbvec-relaxed.csv}\upclrrbvecrelaxed;
        \pgfplotstableread[col sep=comma]{data/update_clone_randomly/std-vec.csv}\upclstdvector;        
        
        \begin{groupplot}[
            group style={group size=2 by 1, horizontal sep=56pt,},                   
            xlabel={Vector size (log scale)},
            ylabel={Mean time (log scale) [\millis{}]},            
            yticklabels={0, \micros{0.1}, \micros{1}, 0.01, 0.1, 1, 10, 100},
            xticklabels={0, 10, 100, \kilo{1}, \kilo{10}, \kilo{100}, \mega{1}},
            ymajorgrids=true, 
            xmajorgrids=true,         
            grid style=dashed,  
        ]
            \nextgroupplot[
                xmode=log,
                ymode=log,
                title={Update randomly},
                legend columns=4,
                legend style={
                    at={(1.06,-0.2)},
                    anchor=north
                }
            ]
            \addplot[ultra thin, color=morange, mark=*, mark size=1.2pt,] table {\upstdvector};            
            \addplot[ultra thin, color=mred, mark=*, mark size=1.2pt,] table {\uprbvecbalanced};            
            \addplot[ultra thin, color=mred, mark=pentagon, mark size=1.6pt,] table {\uprrbvecrelaxed};                     
            \addplot[ultra thin, color=mgreen, mark=square, mark size=1.6pt,] table {\uppvecbalanced};  
            \addplot[ultra thin, color=mgreen, mark=diamond*, mark size=1.2pt,] table {\uppvecrelaxed}; 
            \addplot[ultra thin, color=mpurple, mark=pentagon*, mark size=1.2pt,] table {\upimrsvectorbalanced};            
            \addplot[ultra thin, color=mpurple, mark=square, mark size=1.6pt,] table {\upimrsvectorrelaxed};            
            \legend{\stdvec{}, \rbvec{}, \rrbvec{} \relaxed{}, \pvec{}, \pvec{} \relaxed{}, \imrsvec{}, \imrsvec{} \relaxed{}}
    
            \nextgroupplot[xmode=log,ymode=log,title={Update randomly and cloning}]
            \addplot[ultra thin, color=morange, mark=*, mark size=1.2pt,] table {\upclstdvector};                     
            \addplot[ultra thin, color=mred, mark=*, mark size=1.2pt,] table {\upclrbvecbalanced};            
            \addplot[ultra thin, color=mred, mark=pentagon, mark size=1.6pt,] table {\upclrrbvecrelaxed}; 
            \addplot[ultra thin, color=mgreen, mark=square, mark size=1.6pt,] table {\upclpvecbalanced};
            \addplot[ultra thin, color=mgreen, mark=diamond*, mark size=1.2pt,] table {\upclpvecrelaxed};
            \addplot[ultra thin, color=mpurple, mark=pentagon*, mark size=1.2pt,] table {\upclimrsvectorbalanced};
            \addplot[ultra thin, color=mpurple, mark=square, mark size=1.6pt,] table {\upclimrsvectorrelaxed};                   
        \end{groupplot}
    \end{tikzpicture} 
    \end{adjustbox}

    \caption{Benchmarking results of updating values randomly.}
    \label{fig:update-randomly}
\end{figure}

Even though both \stdvec{}, \pvec{} are faster on average, they are slower than tree-based implementations for the small input range \range{[10, 100]}. This is because tree-based vectors have pre-allocated space for values in the form of tail\todo{ref to background}, while \stdvec{} does not allocate anything on the heap by default. 

\imrsvec{} shows good results too, being faster than \rrbvec{} for smaller inputs in the benchmark without clone. 

\paragraph{Balanced vs relaxed variants}
The overhead of relaxed nodes of \rrbtree{} makes a difference of todox compared to \rbtree{} in the benchmark without clone operation. When clone is used, the difference is negligible at a factor of todox. This shows that the size tables of relaxed nodes do not have a significant impact on performance when cloned. 

\paragraph{Dynamic internal representation}
When tested without clone, a relaxed \pvec{} shows good results and loses only to \stdvec{} with a difference of todox up to 1024, and todox from 1024. 

In the test with clone, \pvec{} outperforms all other tree-based implementations in the \range{[100, \kilo{1}]} range, and outperforms \stdvec{} after surpassing the size of 1024, by using \rrbvec{} internally. For larger inputs in the \range{[\kilo{10}, \kilo{80}]}, \pvec{} and \rrbvec{} are significantly faster than \stdvec{} by todox. 

% TODO: \paragraph{Unique access optimisation}
% TODO: The overhead of relaxed node on path copying.

\subsection{Pushing}
\todo{move the description of benchmarks to the evaluation chapter} 

The push operation is used to append a new value to the end of the vector. It is also responsible for managing the capacity and the internal representation of a vector as the size growth. For example, the \stdvec{} increases its capacity by moving values into a bigger chunk of memory, while \rrbvec{} allocates a new branch and leaf nodes if necessary. \pvec{}, in addition to that, also switches its internal representation depending on the size.

The following benchmarks evaluate how the size and internal representation affect the performance:

\begin{itemize}
    \item Building a new vector from scratch by pushing values into it. 
    \item Pushing values into an existing vector, both balanced and unbalanced. 
\end{itemize}

To understand how vector cloning influences the performance, the use cases above will be extended with a clone operation following every push. 

\subsubsection*{Building a new vector}

\begin{figure}[t]
    \caption{Benchmarking results of push.}
    \label{fig:push}
    
    \center    
    \begin{tikzpicture} 
        \pgfplotstableread[col sep=comma]{data/push/im-rs-vector-balanced.csv}\imrsrbtree;
        \pgfplotstableread[col sep=comma]{data/push/pvec-balanced.csv}\pvecrbtree;        
        \pgfplotstableread[col sep=comma]{data/push/rrbvec-balanced.csv}\rbvec;        
        \pgfplotstableread[col sep=comma]{data/push/std-vec.csv}\std;                 
    
        \begin{loglogaxis}[         
            use units,         
            y unit=s, y unit prefix=m, 
            smooth,        
            width=300pt, % width=\textwidth, 
            title={Push},
            xlabel={vector size (log scale)},
            ylabel={mean time (log scale)},                
            ymajorgrids=true, 
            xmajorgrids=true,
            grid style=dashed,
            legend pos=north west,        
            legend style={draw=none,fill=none,font=\footnotesize},
            legend cell align=left, 
            yticklabel style={
                /pgf/number format/fixed, 
                /pgf/number format/precision=5
            },
            yticklabel={%
                \pgfmathfloatparsenumber{\tick}%
                \pgfmathfloatexp{\pgfmathresult}%
                \pgfmathprintnumber{\pgfmathresult}%
            },
            xticklabels={0, 10, 100, 1K, 10K, 100K, 1M},
            % xticklabel style={/pgf/number format/fixed},		
            % xticklabel={%
            %     \pgfmathfloatparsenumber{\tick}%
            %     \pgfmathfloatexp{\pgfmathresult}%
            %     \pgfmathprintnumber{\pgfmathresult}%
            % },
        ]
            \addplot[thin, color=morange, mark=*,] table {\std}; 
            \addlegendentry{Vec}
    
            \addplot[thin, color=mred, mark=*,] table {\rbvec};
            \addlegendentry{Balanced RrbVec}
    
            \addplot[thin, color=mgreen, mark=square,] table {\pvecrbtree};
            \addlegendentry{Balanced PVec}
    
            \addplot[thin, color=mpurple, mark=pentagon*,] table {\imrsrbtree};
            \addlegendentry{Balanced im-rs Vector}
        \end{loglogaxis}     
    \end{tikzpicture} 
\end{figure}

\begin{figure}[t]
    \caption{Benchmarking results of push clone.}
    \label{fig:push-clone}

    \center
    \begin{tikzpicture} 
        \pgfplotstableread[col sep=comma]{data/push_clone/im-rs-vector-balanced.csv}\imrsrbtree;
        \pgfplotstableread[col sep=comma]{data/push_clone/pvec-balanced.csv}\pvecrbtree;        
        \pgfplotstableread[col sep=comma]{data/push_clone/rrbvec-balanced.csv}\rbvec;        
        \pgfplotstableread[col sep=comma]{data/push_clone/std-vec.csv}\std;                 
    
        \begin{loglogaxis}[         
            use units,         
            y unit=s, y unit prefix=m, 
            smooth,        
            width=300pt,
            title={Push Clone},
            xlabel={vector size (log scale)},
            ylabel={mean time (log scale)},                
            ymajorgrids=true, 
            xmajorgrids=true,
            grid style=dashed,
            legend pos=north west,        
            legend style={draw=none,fill=none,font=\footnotesize},
            legend cell align=left, 
            yticklabel style={
                /pgf/number format/fixed, 
                /pgf/number format/precision=5
            },
            yticklabel={%
                \pgfmathfloatparsenumber{\tick}%
                \pgfmathfloatexp{\pgfmathresult}%
                \pgfmathprintnumber{\pgfmathresult}%
            },
            xticklabel style={/pgf/number format/fixed},		
            xticklabel={%
                \pgfmathfloatparsenumber{\tick}%
                \pgfmathfloatexp{\pgfmathresult}%
                \pgfmathprintnumber{\pgfmathresult}%
            },
        ]
            \addplot[thin, color=morange, mark=*,] table {\std}; 
            \addlegendentry{Vec}
    
            \addplot[thin, color=mred, mark=*,] table {\rbvec};
            \addlegendentry{Balanced RrbVec}
    
            \addplot[thin, color=mgreen, mark=square,] table {\pvecrbtree};
            \addlegendentry{Balanced PVec}
    
            \addplot[thin, color=mpurple, mark=pentagon*,] table {\imrsrbtree};
            \addlegendentry{Balanced im-rs Vector}
        \end{loglogaxis}     
    \end{tikzpicture} 
\end{figure}

The goal is to measure how the vector size influences the push operation performance. The experiment is done by pushing N values into an empty vector, where N is the desired size. N is not used as a hint for predefining the capacity, as persistent implementations do not support it. 

Both \rrbvec{} and \pvec{} will always remain balanced, because the push operation itself does not produce relaxed nodes.

% The assumption is that pvec has similar performance compared to std vec

\paragraph{Dynamic internal representation}
In the input range of [10, 100] \stdvec{} shows the slowest results. Since persistent vectors take advantage of the tail optimization, they do have a preallocated array of fixed size equal to the branching factor, which is set to 32. Since the tree is shallow, the tail push operation will also be relatively fast. On the other hand, \stdvec{} has to increase its capacity several times, which comes at a cost reflected in the results. 

% TODO: check how math notation looks in doc
After the tipping point of N = 100, the \stdvec{} takes the lead by outperforming \pvec{}, \rrbvec{} and \imrsvec{} by a factor of TODOX on average. It is interesting that \pvec{} does not outperform \rrbvec{}, even though it relies on \stdvec{} representation up to the 4096 size. 

% TODO: check if you can reduce the count of times you jump to different parts of memory (such as calls to self.len(), which travels through flavor / arc / heap and back)
This is caused by the overhead of selecting internal representation, which cancels out the benefits of using \stdvec{} for small sizes. The same overhead is apparent after surpassing the 4096 size, where \pvec{} is slightly slower by TODOX compared to \rrbvec{}. 

The \imrsvec{} implementation showed the best results in the range [10, 100] range, but was slower on average by TODOX in comparison to \pvec{}, and by TODOX in comparison to \stdvec{}

\paragraph{Unique access or transience}
Rust's compiler guarantees that mutable references are unique, which supposdely eliminates the possibility of a race condition. Essentially, it means that we can assume that it is safe to modify a vector, as we are the only ones who have a mutable access to it. 

By leveraging this assumption, we can make persistent vector temporarily mutable or emphemeral. This comes with performance benefits, as there is no need to copy or clone the vector after each modification anymore. This behavior is somewhat similar to the transient behavior of the Clojure's persistent vector, even though not entirely the same. 

In the benchmark \todo{ref}, we measure performance of the push operation followed by the explicit clone operation. By cloning a vector, we ensure that following modifications will not affect existing versions. In other words, we will get persistent behavior. 

It is evident that the clone operation is expensive for \stdvec{}, as it simply copies the contents, while persistent vectors take advantage of the structural sharing to minimize the overhead. Balanced \rrbvec{} outperforms \stdvec{} by a factor of TODOX on average, with the performance difference growing proportionally to the size of the vector. 

Unsurprisingly, \pvec{} is slower than both \stdvec{} and \rrbvec{} by a factor of TODOX up to the size of 4096. It does have the same overhead for cloning as \stdvec{}, and has its own overhead for the push operation due to the internal representation logic. 

\imrsvec{} is slower than balanced \rrbvec{} by TODOX, and faster than \pvec{} by TODOX on average. \stdvec{} outperforms it in the [20, 2000] range by, and then degenerates as the size grows. 

\subsubsection*{Adding values to an existing vector}

\begin{figure}[t]
    \caption{Measurements of push for a predefined vector.}
    \label{fig:push-unbalanced}

    \center
    \begin{tikzpicture} 
        \pgfplotstableread[col sep=comma]{data/push_unbalanced/im-rs-vector-balanced.csv}\imrsrbtree;
        \pgfplotstableread[col sep=comma]{data/push_unbalanced/im-rs-vector-unbalanced.csv}\imrsrrbtree;
        \pgfplotstableread[col sep=comma]{data/push_unbalanced/pvec-balanced.csv}\pvecrbtree;
        \pgfplotstableread[col sep=comma]{data/push_unbalanced/pvec-unbalanced.csv}\pvecrrbtree;
        \pgfplotstableread[col sep=comma]{data/push_unbalanced/rrbvec-balanced.csv}\rbvec;
        \pgfplotstableread[col sep=comma]{data/push_unbalanced/rrbvec-unbalanced.csv}\rrbvec;
        \pgfplotstableread[col sep=comma]{data/push_unbalanced/std-vec.csv}\std;    
            
        \begin{loglogaxis}[         
            use units,         
            y unit=s, y unit prefix=m, 
            smooth,        
            width=320pt,
            title={Push for a predefined vector},
            xlabel={vector size (log scale)},
            ylabel={mean time (log scale)},                
            ymajorgrids=true, 
            xmajorgrids=true,
            grid style=dashed,
            legend pos=north west,        
            legend style={draw=none,fill=none,font=\footnotesize},
            legend cell align=left, 
            yticklabel style={
                /pgf/number format/fixed, 
                /pgf/number format/precision=5
            },
            yticklabel={%
                \pgfmathfloatparsenumber{\tick}%
                \pgfmathfloatexp{\pgfmathresult}%
                \pgfmathprintnumber{\pgfmathresult}%
            },
            xticklabels={0, 10, 100, 1K, 10K, 100K},
            % xticklabel style={/pgf/number format/fixed},		
            % xticklabel={%
            %     \pgfmathfloatparsenumber{\tick}%
            %     \pgfmathfloatexp{\pgfmathresult}%
            %     \pgfmathprintnumber{\pgfmathresult}%
            % },
        ]
            \addplot[thin, color=morange, mark=*,] table {\std}; 
            \addlegendentry{Vec}
    
            \addplot[thin, color=mred, mark=*,] table {\rbvec};
            \addlegendentry{Balanced RrbVec}
    
            \addplot[thin, color=mred, mark=pentagon,] table {\rrbvec}; 
            \addlegendentry{Unbalanced RrbVec}
    
            \addplot[thin, color=mgreen, mark=square,] table {\pvecrbtree};
            \addlegendentry{Balanced PVec}
    
            \addplot[thin, color=mgreen, mark=diamond*,] table {\pvecrrbtree};
            \addlegendentry{Unbalanced PVec}
    
            \addplot[thin, color=mpurple, mark=pentagon*,] table {\imrsrbtree};
            \addlegendentry{Balanced im-rs Vector}
    
            \addplot[thin, color=mpurple, mark=square,] table {\imrsrrbtree};
            \addlegendentry{Unbalanced im-rs Vector} 
        \end{loglogaxis}     
    \end{tikzpicture} 
\end{figure}

\begin{figure}[t]
    \caption{Measurements of push and clone for a predefined vector.}
    \label{fig:push-clone-unbalanced}

    \center
    \begin{tikzpicture} 
        \pgfplotstableread[col sep=comma]{data/push_clone_unbalanced/im-rs-vector-balanced.csv}\imrsrbtree;
        \pgfplotstableread[col sep=comma]{data/push_clone_unbalanced/im-rs-vector-unbalanced.csv}\imrsrrbtree;
        \pgfplotstableread[col sep=comma]{data/push_clone_unbalanced/pvec-balanced.csv}\pvecrbtree;
        \pgfplotstableread[col sep=comma]{data/push_clone_unbalanced/pvec-unbalanced.csv}\pvecrrbtree;
        \pgfplotstableread[col sep=comma]{data/push_clone_unbalanced/rrbvec-balanced.csv}\rbvec;
        \pgfplotstableread[col sep=comma]{data/push_clone_unbalanced/rrbvec-unbalanced.csv}\rrbvec;
        \pgfplotstableread[col sep=comma]{data/push_clone_unbalanced/std-vec.csv}\std;    
            
        \begin{loglogaxis}[         
            use units,         
            y unit=s, y unit prefix=m, 
            smooth,        
            width=320pt,
            title={Push and clone for a predefined vector},
            xlabel={vector size (log scale)},
            ylabel={mean time (log scale)},                
            ymajorgrids=true, 
            xmajorgrids=true,
            grid style=dashed,
            legend pos=north west,        
            legend style={draw=none,fill=none,font=\footnotesize},
            legend cell align=left, 
            yticklabel style={
                /pgf/number format/fixed, 
                /pgf/number format/precision=5
            },
            yticklabel={%
                \pgfmathfloatparsenumber{\tick}%
                \pgfmathfloatexp{\pgfmathresult}%
                \pgfmathprintnumber{\pgfmathresult}%
            },
            xticklabels={0, 10, 100, 1K, 10K},
            % xticklabel style={/pgf/number format/fixed},		
            % xticklabel={%
            %     \pgfmathfloatparsenumber{\tick}%
            %     \pgfmathfloatexp{\pgfmathresult}%
            %     \pgfmathprintnumber{\pgfmathresult}%
            % },
        ]
            \addplot[thin, color=morange, mark=*,] table {\std}; 
            \addlegendentry{Vec}
    
            \addplot[thin, color=mred, mark=*,] table {\rbvec};
            \addlegendentry{Balanced RrbVec}
    
            \addplot[thin, color=mred, mark=pentagon,] table {\rrbvec}; 
            \addlegendentry{Unbalanced RrbVec}
    
            \addplot[thin, color=mgreen, mark=square,] table {\pvecrbtree};
            \addlegendentry{Balanced PVec}
    
            \addplot[thin, color=mgreen, mark=diamond*,] table {\pvecrrbtree};
            \addlegendentry{Unbalanced PVec}
    
            \addplot[thin, color=mpurple, mark=pentagon*,] table {\imrsrbtree};
            \addlegendentry{Balanced im-rs Vector}
    
            \addplot[thin, color=mpurple, mark=square,] table {\imrsrrbtree};
            \addlegendentry{Unbalanced im-rs Vector}
        \end{loglogaxis}     
    \end{tikzpicture} 
\end{figure}

To understand the effect of relaxed nodes on the push operation, the setup routine produces an unbalanced vector of size N, created by concatenating a number of small vectors together. 

There are two variants of the test: the first one is pushing values onto provided vector, while the second one also performs clone. 

\paragraph{Balanced vs unbalanced} As shown in \ref{fig:push-unbalanced}, the difference in performance between balanced and unbalanced variants is negligible, mostly because pushing new values creates balanced nodes. 

\paragraph{Dynamic internal representation}
As in case with \ref{fig:push}, dynamic internal representation of \pvec{} hardly makes any difference in performance. The benefits of using \stdvec{} for small sizes simply is cancelled out by the overhead of choosing the representation. 

\paragraph{Unique access or transience}
% What do I right here? Maybe I don't really need to have this push_clone_unbalanced bench at all?

\stdvec{} showed the best results in \ref{fig:push-unbalanced} test. It was TODOX faster on average in comparison to the fastest runner up, balanced \rrbvec{}. \imrsvec{} was marginally slower by TODOX in comparison to \pvec{}. 

\subsection{Popping}
% What and why are we measuring?
The pop operation is used to remove values at the end of the vector. As with push, it is responsible for managing the capacity of the underlying data structure. For \stdvec{} it means shrinking the array and copying elements over. As persistent vector is based on \rrbtree{}, it implies deallocating nodes and reducing the height of the tree when necessary. 

% Which flavors of benchmarks are we going to have?
Pop will be tested in two benchmarks, namely pop and pop clone. The first test implies calling pop continiously in the loop, until the vector is emptied. In the second benchmark, each pop operation will be followed by clone. Both benchmarks will be executed on balanced and unbalanced variants of vectors. 

% Drawing conclusions from numbers

\paragraph{Dynamic internal representation}
% content

\paragraph{Unique access and transience}
% content

\subsection{Concatenating}
% What and why are we measuring?
The concat operation takes another instance of vector and merges its contents into the former(?) vector. 

Concatenation is one of the fundamental operations which make \rrbvec{} a confluently persistent data structure. We (?) claimed that performance of the concat operation is O(log(n)), in comparison to O(max(a,b)) for \stdvec{}. 

One of the research questions was to check whether persistent concat beats the standard one in practice. The experiment is to simply concatenate several vectors of different size together. The benchmark is parameterized over the size of the resulting vector, which will be in the [10, 1M] range. 

% Which flavors of benchmarks are we going to have?
As the concat operation creates relaxed nodes, only unbalanced (or relaxed) variants of vectors will be evaluated. That implies \stdvec{}, \imrsvec{}, \rrbvec{} and \pvec{}. 

% Drawing conclusions from numbers
Suprisingly, the \stdvec{} beats the \rrbvec{} and \imrsvec up to the size of TODOX. It is evident that the cost of concatenating persistent vectors does not grow as fast as for the standard vector. Unfortunately, this happens only at the point where size is TODOX, which is a quite large value. 

The dynamic internal representation of \pvec{} puts it into advantage by a factor of TODOX in comparison to \rrbvec{}, and by TODOX compared to \imrsvec{} implementation. It is clear that at the size of 4096, \pvec{} switches its internal representation to \rrbvec{}. 

% TODO: consider adding append_clone back. It can put things into perspective of how expensive it would be to use stdvec as immutable (but is this really meaningful?)

\subsection{Slicing}
% TODO: the bug in the im-rs has to be fixed first

\subsection{Rc vs Arc}
\label{sec:perf-rc-vs-arc}
\stdvec{} is not included in the comparison, as its implementation does not rely on the reference counted pointers. 

\section{Performance in parallel benchmarks}
\label{sec:perf-par}

The expectation from parallel benchmarks is to reveal whether proposed optimizations were effective in the parallel context. 

First, if confluent concatenation and split operations of \rrbvec{} are faster compared to \rbvec{}. And second, whether the dynamic internal representation has positive impact on the overall performance of \pvec{}. 

At last, we will evaluate the impact of increasing number of threads on the performance. 

The results are presented in the form of three-dimensional graph, where x and y axis correspond to the problem size and number of threads used, while z is used for the mean run time. 

\subsection{Adding elements of two vectors.} 

\begin{figure}[!htbp]

    \center
    \begin{tikzpicture} 
        \tikzstyle{every node}=[
            font=\footnotesize, 
            inner sep=2pt,
            outer sep=0pt            
        ]        

        \begin{loglogaxis}[         
            use units,         
            z unit=s, z unit prefix=m,
            smooth,        
            width=320pt,            
            title style={align=center},
            title={Time comparison of incrementing numbers of the N sized vector\\ parallelised on K number of threads.},
            ymajorgrids=true, 
            xmajorgrids=true,
            zmajorgrids=true,
            xlabel={vector size (log scale)},
            ylabel={number of threads (log scale)},           
            zlabel={mean time (log scale)},                               
            grid style=dashed,
            legend pos=outer north east,        
            legend style={fill=none,font=\footnotesize},
            legend cell align=left,            
            ytick={1, 2, 4, 8},       
            xticklabels={10, 100, 1K, 10K},          
            yticklabels={1, 2, 4, 8},         
            zticklabel style={
                /pgf/number format/fixed, 
                /pgf/number format/precision=2
            },   
            zticklabel={%
                \pgfmathfloatparsenumber{\tick}%
                \pgfmathfloatexp{\pgfmathresult}%
                \pgfmathprintnumber{\pgfmathresult}%
            },            
            view={-45}{8},
        ]            
            \addplot3[surf, mesh/rows=4, opacity=0.1, fill opacity=0.3, color=mred] table [x={size}, y={threads}, z={time}, col sep=comma] {data/vector_addition/std-vec.csv}; 
            \addlegendentry{Vec}

            \addplot3[surf, mesh/rows=4, opacity=0.1, fill opacity=0.3, color=morange] table [x={size}, y={threads}, z={time}, col sep=comma] {data/vector_addition/rrbvec-balanced.csv}; 
            \addlegendentry{RbVec}

            \addplot3[surf, mesh/rows=4, opacity=0.1, fill opacity=0.3, color=blue] table [x={size}, y={threads}, z={time}, col sep=comma] {data/vector_addition/rrbvec-unbalanced.csv}; 
            \addlegendentry{RrbVec}

            \addplot3[surf, mesh/rows=4, opacity=0.1, fill opacity=0.3, color=mgreen] table [x={size}, y={threads}, z={time}, col sep=comma] {data/vector_addition/pvec-unbalanced.csv}; 
            \addlegendentry{PVec}
        \end{loglogaxis}     
    \end{tikzpicture} 

    \label{fig:map-fold}
    \caption{Incrementing each element of a vector on multiple threads.}    
\end{figure}

% NOTE: you can justify this by the goal of minimizing the overhead of the actual computation, to have a simpler way to compare different vector implementations. 

% TODO:
%  - Consider using tables with runtime numbers

\paragraph{Balanced vs unbalanced}
\rbvec{} and \rrbvec{} show nearly identical results in sequential benchmarks. This is expected, as concat and split operations which create relaxed nodes were not used. Hence, \rrbvec{} remains balanced throughout the test, and is backed by the same representation of \rrbtree{} as \rbvec{}. Both variants are consistently slower compared to \stdvec{} with a difference of 3.2-3.5x on average. 

When executed in parallel, \rrbvec{} starts outperforming \rbvec{} at the size of 1024 elements. The reason why difference becomes apparent after surpassing that size, is because concatenation algorithm used in this project, produces balanced \rbtree{} when the height of the tree does not exceed two levels. With branching factor of 32, capacity of the tree of two levels is equal to 1024. 

As the vector size growth, Rayon performs more splits to achieve optimal vector size per a single thread. This, in a turn, results in a higher number of concatenations necessary to combine execution results. Since \rbvec{} has naive implementation of concat and split, its performance degrades with the input size growth. The difference in execution time depending on size falls into the 1.0-2.3x range. 

To keep available threads busy, Rayon divides the available pool of work into smaller pieces. Hence, the growing number of threads increases the performance gap between \rbvec{} and \rrbvec{} even further, as split and concat are used more frequently. In the test with 2, 4 and 8 threads, \rbvec{} is slower than \rrbvec{} by a factor of 1.0-2.3x, 1.0-2.8x, and 1.1-2.12x correspondingly. 

\paragraph{Dynamic internal representation}
\pvec{} consistently demonstrates better results compared to \rrbvec{}. This can be explained by the fact that it uses \stdvec{} as its internal representation until the concatenation stage, during which it upgrades to \rrbvec{}. In the sequential benchmark, \pvec{} is faster compared to \rrbvec{} by 1.7-2.0x. When parallelised on 4 threads, \rrbvec{} becomes slightly more efficient due to the higher count of concats and splits, with the difference at 1.3-1.8x. 

Even though \rrbvec{}'s concat and split operations are faster for the large sized vectors, \stdvec{} showed the best results in all tests. It is important to keep in mind that concats and splits substitute only a small portion of all operations used in this test. Operations such as get and push, which were extensively used in this benchmark, are still faster for \stdvec{}. Thus, the closest runner up -- \pvec{}, is slower by 1.8-1.9x and 1.6-1.7x in the sequential and 4-threaded parallel benchmarks correspondingly. 

\paragraph{Effect of parallelism}
% TODO: this is not entirely true, because 4 threads benchmark runs slightly faster for large datasets compared to sequential bench.  
Interestingly enough, the sequential variant of the benchmark outperformed all subsequent parallel tests. This can be explained by the overhead induced by distribution of work between multiple threads, which outweighs the benefits of solving a relatively simple problem in parallel.

\subsection{Check if a word is a palindrome}

\begin{figure}[!htbp]

    \center
    \begin{tikzpicture} 
        \tikzstyle{every node}=[
            font=\footnotesize, 
            inner sep=2pt,
            outer sep=0pt            
        ]        

        \begin{loglogaxis}[         
            use units,         
            z unit=s, z unit prefix=m,
            smooth,        
            width=320pt,            
            title style={align=center},
            title={Time comparison of incrementing numbers of the N sized vector\\ parallelised on K number of threads.},
            ymajorgrids=true, 
            xmajorgrids=true,
            zmajorgrids=true,
            xlabel={vector size (log scale)},
            ylabel={number of threads (log scale)},           
            zlabel={mean time (log scale)},                               
            grid style=dashed,
            legend pos=outer north east,        
            legend style={fill=none,font=\footnotesize},
            legend cell align=left,            
            ytick={1, 2, 4, 8},       
            xticklabels={10, 100, 1K, 10K},          
            yticklabels={1, 2, 4, 8},         
            zticklabel style={
                /pgf/number format/fixed, 
                /pgf/number format/precision=2
            },   
            zticklabel={%
                \pgfmathfloatparsenumber{\tick}%
                \pgfmathfloatexp{\pgfmathresult}%
                \pgfmathprintnumber{\pgfmathresult}%
            },            
            view={-45}{8},
        ]            
            \addplot3[surf, mesh/rows=4, opacity=0.1, fill opacity=0.3, color=mred] table [x={size}, y={threads}, z={time}, col sep=comma] {data/words_map/std-vec.csv}; 
            \addlegendentry{Vec}

            \addplot3[surf, mesh/rows=4, opacity=0.1, fill opacity=0.3, color=morange] table [x={size}, y={threads}, z={time}, col sep=comma] {data/words_map/rrbvec-balanced.csv}; 
            \addlegendentry{RbVec}

            \addplot3[surf, mesh/rows=4, opacity=0.1, fill opacity=0.3, color=blue] table [x={size}, y={threads}, z={time}, col sep=comma] {data/words_map/rrbvec-unbalanced.csv}; 
            \addlegendentry{RrbVec}

            \addplot3[surf, mesh/rows=4, opacity=0.1, fill opacity=0.3, color=mgreen] table [x={size}, y={threads}, z={time}, col sep=comma] {data/words_map/pvec-unbalanced.csv}; 
            \addlegendentry{PVec}
        \end{loglogaxis}     
    \end{tikzpicture} 

    \label{fig:map-fold}
    \caption{Incrementing each element of a vector on multiple threads.}    
\end{figure}

\paragraph{Balanced vs unbalanced}
As expected, \rbvec{} and \rrbvec{} are equally fast in the sequential test as both of them are backed by a balanced \rbtree{}. When benchmark is parallelised, \rrbvec{} gains advantage due to its efficient split and concat operations. The difference between variants grows along with the increasing count of threads. Specifically, it is 1.5-2.0x for the test run with 2 threads, and 1.7-2.5x for 4 threads.

\paragraph{Dynamic internal representation}
Results show that \pvec{} outperforms \rbvec{} and \rrbvec{} for all vector sizes and thread configurations. When it comes to \stdvec{}, \pvec{} shows 1.4x slower run time at the input size of 10000 words, after which it catches up and surpasses \stdvec{} at the mark of 200000 words. For the biggest problem size of 370103 words, \pvec{} outperforms \stdvec{} with a difference of 1.1x. 

The increase in the thread count, causes higher count of vector splits and concats. Thus, the bigger the problem size and the thread count is, the more advantages \pvec{} provides, demonstrating performance results comparables to \stdvec{}. 

\paragraph{Effect of parallelism}
Interestingly enough, the sequential variant of the benchmark outperformed all subsequent parallel tests. This can be explained by the overhead induced by distribution of work between multiple threads, which outweighs the benefits of solving a relatively simple problem in parallel.

\section{Discussion}

% Indexing
% * Iterators are faster than sequential index

\subsection{Overhead of RRB Tree}
% Indexing:
% * Relaxed nodes introduce enough overhead to make 
%      a noticeable difference in operations by index
% * Relaxed nodes do not affect iterator implementations

\subsection{Unique access or transience}
\subsection{Dynamic internal representation}
% Indexing:
%  * PVec is slower than Vec (both up to and after thresholds)
%   * In random access test, perf difference is negligible. Vec loses its advantage due to cache invalidation. 
%  * PVec is faster than RbVec, and RrbVec by TODOX. 

\subsection{Parallel vector}

% NOTE: as the size of the vector values increases, persistent version starts gaining advantage compared to \stdvec{}, as \stdvec{}'s split and append operations are relying on memory copying / allocation. 